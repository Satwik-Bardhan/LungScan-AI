{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5d7e43",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd493b2",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c982e44-b773-4927-ac64-d2ce1c3e35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5158d0",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2cc59",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337cc78",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3798 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,  #feature scaling to each and every value by diving all value 255 .\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(r\"D:\\PROJECT\\LIPS\\DataSet\\train\",\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode = 'grayscale'  # Add this if images are grayscale\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6593e2",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbc1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 951 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r\"D:\\PROJECT\\LIPS\\DataSet\\test\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,  #how many images in each batch\n",
    "                                            class_mode = 'categorical',\n",
    "                                           color_mode = 'grayscale'  # Add this if images are grayscale\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bfa07",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "# Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c6090-188a-4d0c-bc66-c6b4ca77bcd2",
   "metadata": {},
   "source": [
    "### Adding the first convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a0289",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([tf.keras.layers.Input(shape=(64, 64, 3)), tf.keras.layers.Conv2D(32, (3, 3), activation='relu')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4dfba",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56875612",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75bce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d610ac",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbc4fe",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "#rectifier activation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3247d82c",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f30efe",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "# Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e449fc",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef615d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss ='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ba77e",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import PyDataset\n",
    "\n",
    "class CustomDataset(PyDataset):\n",
    "    def __init__(self, data, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd44316",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "# Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd410d57-3d95-4848-85b3-9114a949d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.build(input_shape=(None, 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('D:\\PROJECT\\LIPS\\model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e264d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HEALTHY': 0, 'PNEUMONIA': 1, 'TUBERCULOSIS': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img(r\"D:\\PROJECT\\LIPS\\DataSet\\test\\PNEUMONIA\\005.jpeg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argmax(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c52d3-ef9c-48eb-a1ac-16d5ed7302fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROJECT\\LIPS\\my_venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the trained model\n",
    "from tensorflow.keras.models import load_model\n",
    "cnn = load_model('model.keras')\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = {0: 'HEALTHY', 1: 'PNEUMONIA', 2: 'TUBERCULOSIS'}\n",
    "\n",
    "# Function to make predictions\n",
    "@tf.function\n",
    "def predict(image_path):\n",
    "    test_image = image.load_img(image_path, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = cnn(test_image)  # Call the model directly on the input\n",
    "    label_index = tf.argmax(result, axis=1)  # Find the index of the maximum value\n",
    "    return label_index\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"D:\\PROJECT\\LIPS\\DataSet\\test\\TUBERCULOSIS\\t006.jpg\"\n",
    "result = predict(image_path)\n",
    "prediction_index = result.numpy()[0]\n",
    "prediction_label = class_labels[prediction_index]\n",
    "print(\"Prediction:\", prediction_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12308f0-e035-46e8-bf7b-bfad97be39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    test_image = image.load_img(image_path, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = test_image / 255.0  # Normalize pixel values\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = cnn(test_image)\n",
    "    label_index = tf.argmax(result, axis=-1)\n",
    "    return label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe670725-569d-43c0-bbe8-225cbfefd66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\PROJECT\\\\LIPS\\\\DataSet\\\\test\\\\TUBERCULOSIS\\\\048.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_image = \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mD:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mPROJECT\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mLIPS\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDataSet\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mTUBERCULOSIS\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m048.jpeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m plt.imshow(test_image)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mInput Image\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\PROJECT\\LIPS\\my_venv\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:235\u001b[39m, in \u001b[36mload_img\u001b[39m\u001b[34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib.Path):\n\u001b[32m    234\u001b[39m         path = \u001b[38;5;28mstr\u001b[39m(path.resolve())\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    236\u001b[39m         img = pil_image.open(io.BytesIO(f.read()))\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'D:\\\\PROJECT\\\\LIPS\\\\DataSet\\\\test\\\\TUBERCULOSIS\\\\048.jpeg'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_image = image.load_img(r\"D:\\PROJECT\\LIPS\\DataSet\\test\\TUBERCULOSIS\\048.jpeg\", target_size=(64, 64))\n",
    "plt.imshow(test_image)\n",
    "plt.title(\"Input Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0ff89-b6ac-444d-bd94-dc8c787bcf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = load_model('model.keras', compile=False)\n",
    "cnn.summary()  # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208bb13-e0a8-4a64-a25c-e9989ea257c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da4b86-8c8c-4f0f-a51d-b4b8962d90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "base_model.trainable = False  # Freeze layers\n",
    "\n",
    "cnn = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d43c6-27d4-46ef-b8a1-46976557da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da1894-d1ac-4f12-9517-1d53a959a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    test_image = image.load_img(image_path, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image) / 255.0\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    probabilities = cnn.predict(test_image)[0]\n",
    "    predicted_class = np.argmax(probabilities)\n",
    "    print(f\"Probabilities: {probabilities}\")\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if np.argmax(result[0])==0:\n",
    "#     print(\"HEALTHY\")\n",
    "# elif np.argmax(result[0])==1:\n",
    "#     print(\"PNEUMONIA\")\n",
    "# else:\n",
    "#     print(\"TUBERCULOSIS\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "855d81ef",
   "metadata": {},
   "source": [
    "Ploting graph and cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'], label='Training Loss')  \n",
    "plt.plot(h.history['val_loss'], label='Validation Loss')  \n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = np.argmax(cnn.predict(test_set),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(test_set,axis=1),pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-KERNEL",
   "language": "python",
   "name": "ml-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
